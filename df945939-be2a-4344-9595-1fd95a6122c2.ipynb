{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "  \n",
    "Thank you for taking the time to improve the project! Now it's accepted. Good luck on the next sprint!\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a great job overall, but one task is missing: the mathematical proof that data obfuscation does not influence the model's quality. I gave you some hints, but if you still have trouble with it, contact the tutor. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sure Tomorrow insurance company wants to solve several tasks with the help of Machine Learning and you are asked to evaluate that possibility.\n",
    "\n",
    "- Task 1: Find customers who are similar to a given customer. This will help the company's agents with marketing.\n",
    "- Task 2: Predict whether a new customer is likely to receive an insurance benefit. Can a prediction model do better than a dummy model?\n",
    "- Task 3: Predict the number of insurance benefits a new customer is likely to receive using a linear regression model.\n",
    "- Task 4: Protect clients' personal data without breaking the model from the previous task. It's necessary to develop a data transformation algorithm that would make it hard to recover personal information if the data fell into the wrong hands. This is called data masking, or data obfuscation. But the data should be protected in such a way that the quality of machine learning models doesn't suffer. You don't need to pick the best model, just prove that the algorithm works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ol>\n",
    "      <li><a href=\"#1\">Data Preprocessing & EDA</a></li>\n",
    "      <li><a href=\"#2\">Task 1. Similar Customers</a></li>\n",
    "      <li><a href=\"#3\">Task 2. Is Customer Likely to Receive Insurance Benefit?</a></li>\n",
    "      <li><a href=\"#4\">Task 3. Regression (with Linear Regression)</a></li>\n",
    "      <li><a href=\"#5\">Task 4. Obfuscating Data</a></li>\n",
    "      <li><a href=\"#6\"> Conclusions</a></li>\n",
    "    </ol> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\"> Data Preprocessing & Exploration\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and conduct a basic check that it's free from obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rename the colums to make the code look more consistent with its style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4557</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1899</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3228</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4043</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4903</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2316</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3571</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2268</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age   income  family_members  insurance_benefits\n",
       "4557       1  41.0  54000.0               4                   0\n",
       "1899       0  18.0  38000.0               2                   0\n",
       "3228       1  41.0  32300.0               0                   0\n",
       "4043       1  29.0  48100.0               2                   0\n",
       "4903       1  18.0  32800.0               1                   0\n",
       "2993       0  36.0  42000.0               0                   0\n",
       "2316       1  52.0  54700.0               0                   2\n",
       "3571       0  35.0  25700.0               1                   0\n",
       "2268       1  44.0  28400.0               0                   1\n",
       "299        0  39.0  43500.0               3                   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      "gender                5000 non-null int64\n",
      "age                   5000 non-null float64\n",
      "income                5000 non-null float64\n",
      "family_members        5000 non-null int64\n",
      "insurance_benefits    5000 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may want to fix the age type (from float to int) though this is not critical\n",
    "# write your conversion here if you choose:\n",
    "df['age'] = df['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      "gender                5000 non-null int64\n",
      "age                   5000 non-null int64\n",
      "income                5000 non-null float64\n",
      "family_members        5000 non-null int64\n",
      "insurance_benefits    5000 non-null int64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "# check to see that the conversion was successful\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>30.952800</td>\n",
       "      <td>39916.360000</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.440807</td>\n",
       "      <td>9900.083569</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.463183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        income  family_members  \\\n",
       "count  5000.000000  5000.000000   5000.000000     5000.000000   \n",
       "mean      0.499000    30.952800  39916.360000        1.194200   \n",
       "std       0.500049     8.440807   9900.083569        1.091387   \n",
       "min       0.000000    18.000000   5300.000000        0.000000   \n",
       "25%       0.000000    24.000000  33300.000000        0.000000   \n",
       "50%       0.000000    30.000000  40200.000000        1.000000   \n",
       "75%       1.000000    37.000000  46600.000000        2.000000   \n",
       "max       1.000000    65.000000  79000.000000        6.000000   \n",
       "\n",
       "       insurance_benefits  \n",
       "count         5000.000000  \n",
       "mean             0.148000  \n",
       "std              0.463183  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              5.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now have a look at the data's descriptive statistics. \n",
    "# Does everything look okay?\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age   income  family_members  insurance_benefits\n",
       "0       1   41  49600.0               1                   0\n",
       "1       0   46  38000.0               1                   1\n",
       "2       0   29  21000.0               0                   0\n",
       "3       0   21  41700.0               2                   0\n",
       "4       1   28  26100.0               0                   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                0\n",
       "age                   0\n",
       "income                0\n",
       "family_members        0\n",
       "insurance_benefits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- The data looks good:\n",
    "    - it contains 5000 rows and 5 columns\n",
    "    - we renamed the colums to make the code look more consistent with its style.\n",
    "    - we fixed the age type (from float to int)\n",
    "    - we found no missing values\n",
    "    \n",
    "Let's move on to the EDA part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check whether there are certain groups of customers by looking at the pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it is a bit difficult to spot obvious groups (clusters) as it is difficult to combine several variables simultaneously (to analyze multivariate distributions). That's where LA and ML can be quite handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"2\"> Task 1. Similar Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the language of ML, it is necessary to develop a procedure that returns k nearest neighbors (objects) for a given object based on the distance between the objects.\n",
    "\n",
    "You may want to review the following lessons (chapter -> lesson)\n",
    "- Distance Between Vectors -> Euclidean Distance\n",
    "- Distance Between Vectors -> Manhattan Distance\n",
    "\n",
    "To solve the task, we can try different distance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that returns k nearest neighbors for an $n^{th}$ object based on a specified distance metric. The number of received insurance benefits should not be taken into account for this task. \n",
    "\n",
    "You can use a ready implementation of the kNN algorithm from scikit-learn (check [the link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) or use your own.\n",
    "\n",
    "Test it for four combination of two cases\n",
    "- Scaling\n",
    "  - the data is not scaled\n",
    "  - the data is scaled with the [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) scaler\n",
    "- Distance Metrics\n",
    "  - Euclidean\n",
    "  - Manhattan\n",
    "\n",
    "Answer these questions:\n",
    "- Does the data being not scaled affect the kNN algorithm? If so, how does that appear?\n",
    "- How similar are the results using the Manhattan distance metric (regardless of the scaling)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns k nearest neighbors\n",
    "\n",
    "    :param df: pandas DataFrame used to find similar objects within\n",
    "    :param n: object no for which the nearest neighbours are looked for\n",
    "    :param k: the number of the nearest neighbours to return\n",
    "    :param metric: name of distance metric\n",
    "    \"\"\"\n",
    "\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k, metric=metric) \n",
    "    nbrs.fit(df[feature_names].values)\n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "The function for getting k nearest neighbors is correct\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.387342</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.535443</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits\n",
       "2350     0.0  0.307692  0.565823        0.166667                   0\n",
       "1599     1.0  0.753846  0.387342        0.666667                   1\n",
       "2630     1.0  0.430769  0.613924        0.000000                   0\n",
       "3909     1.0  0.507692  0.493671        0.500000                   0\n",
       "1999     1.0  0.523077  0.535443        0.500000                   0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get similar records for a given one for every combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4031</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3424</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.316625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4661</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2349</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.099020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age   income  family_members  distance\n",
       "0          1   41  49600.0               1  0.000000\n",
       "2022       1   41  49600.0               0  1.000000\n",
       "1225       0   42  49600.0               0  1.732051\n",
       "4031       1   44  49600.0               2  3.162278\n",
       "3424       0   38  49600.0               0  3.316625\n",
       "815        1   37  49600.0               2  4.123106\n",
       "4661       0   45  49600.0               0  4.242641\n",
       "2125       0   37  49600.0               2  4.242641\n",
       "2349       1   46  49600.0               2  5.099020\n",
       "3900       1   36  49600.0               0  5.099020"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# euclidean distance with unscaled data\n",
    "get_knn(df[feature_names], 0, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.634177</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.018418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.028550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.029624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.635443</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  distance\n",
       "0        1.0  0.630769  0.627848        0.166667  0.000000\n",
       "2689     1.0  0.630769  0.634177        0.166667  0.006329\n",
       "133      1.0  0.615385  0.636709        0.166667  0.017754\n",
       "4869     1.0  0.646154  0.637975        0.166667  0.018418\n",
       "3275     1.0  0.646154  0.651899        0.166667  0.028550\n",
       "1567     1.0  0.615385  0.602532        0.166667  0.029624\n",
       "2103     1.0  0.630769  0.596203        0.166667  0.031646\n",
       "3365     1.0  0.630769  0.596203        0.166667  0.031646\n",
       "124      1.0  0.661538  0.635443        0.166667  0.031693\n",
       "3636     1.0  0.615385  0.600000        0.166667  0.031815"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# euclidean distance with scaled data\n",
    "get_knn(df_scaled[feature_names], 0, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4031</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3424</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2349</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4661</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age   income  family_members  distance\n",
       "0          1   41  49600.0               1       0.0\n",
       "2022       1   41  49600.0               0       1.0\n",
       "1225       0   42  49600.0               0       3.0\n",
       "4031       1   44  49600.0               2       4.0\n",
       "815        1   37  49600.0               2       5.0\n",
       "3424       0   38  49600.0               0       5.0\n",
       "2125       0   37  49600.0               2       6.0\n",
       "3900       1   36  49600.0               0       6.0\n",
       "2349       1   46  49600.0               2       6.0\n",
       "4661       0   45  49600.0               0       6.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manhattan (city block) distance with unscaled data\n",
    "get_knn(df[feature_names], 0, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.634177</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.024245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.025511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.635443</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.038364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.588608</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.039241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.039435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.040701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  distance\n",
       "0        1.0  0.630769  0.627848        0.166667  0.000000\n",
       "2689     1.0  0.630769  0.634177        0.166667  0.006329\n",
       "133      1.0  0.615385  0.636709        0.166667  0.024245\n",
       "4869     1.0  0.646154  0.637975        0.166667  0.025511\n",
       "3365     1.0  0.630769  0.596203        0.166667  0.031646\n",
       "2103     1.0  0.630769  0.596203        0.166667  0.031646\n",
       "124      1.0  0.661538  0.635443        0.166667  0.038364\n",
       "4305     1.0  0.630769  0.588608        0.166667  0.039241\n",
       "3275     1.0  0.646154  0.651899        0.166667  0.039435\n",
       "1567     1.0  0.615385  0.602532        0.166667  0.040701"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manhattan (city block) distance with scaled data\n",
    "get_knn(df_scaled[feature_names], 0, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the data being not scaled affect the kNN algorithm? If so, how does that appear?** \n",
    "\n",
    "- The unscaled data affects the kNN algorithm because the algorithm is giving more importance features with higher ranging numbers. \n",
    "- In the task using euclidean distance, \n",
    "    - for unscaled data, the distance metric calculated ranges from 0.00 to 5.09, \n",
    "    - for scaled data, the distance metric range of 0.00 to 0.03. \n",
    "- This shows the impact of data scaling. \n",
    "- With data scaling, the distances are now more comparable than they were before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Yep, exactly!\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How similar are the results using the Manhattan distance metric (regardless of the scaling)?** \n",
    "\n",
    "We can see just the 1st NN that is identical when applying Manhattan distance metric, the rest of the results are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Not sure if you've understood the question correctly. The task means to compare the results with euclidean metric (applied to unscaled/scaled data) to the results with manhattan metric (applied to unscaled data). They look pretty similar to me. For example (on scaled data) with both euclidean and manhattan metric the top 3 neighbors of 0 are 2689, 133, 4869\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Thank you, I thought it was about just the Manhattan distance, yes indeed!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\"> Task 2. Is Customer Likely to Receive Insurance Benefit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of machine learning we can look at this like a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `insurance_benefits` being more than zero as the target, evaluate whether the kNN classification approach can do better than a dummy model.\n",
    "\n",
    "Instructions:\n",
    "- Build a KNN-based classifier and measure its quality with the F1 metric for k=1..10 for both the original data and the scaled one. That'd be interesting to see how k may influece the evaluation metric, and whether scaling the data makes any difference. You can use a ready implemention of the kNN classification algorithm from scikit-learn (check [the link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) or use your own.\n",
    "- Build the dummy model which is just random for this case. It should return \"1\" with some probability. Let's test the model with four probability values: 0, the probability of paying any insurance benefit, 0.5, 1.\n",
    "\n",
    "The probability of paying any insurance benefit can be defined as\n",
    "\n",
    "$$\n",
    "P\\{\\text{insurance benefit received}\\}=\\frac{\\text{number of clients received any insurance benefit}}{\\text{total number of clients}}.\n",
    "$$\n",
    "\n",
    "Split the whole data in the 70:30 proportion for the training/testing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the target\n",
    "df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)\n",
    "#<your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Yep, that's correct\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4436\n",
       "1     564\n",
       "Name: insurance_benefits_received, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the class imbalance with value_counts()\n",
    "df['insurance_benefits_received'].value_counts()\n",
    "# <your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    print('Confusion Matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating output of a random model\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure F1 metric on original data using KNN-based classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "train, test = train_test_split(df, test_size=0.3, stratify=df['insurance_benefits_received'], random_state=12345)\n",
    "\n",
    "X_train = train[feature_names]\n",
    "X_test = test[feature_names]\n",
    "y_train = train['insurance_benefits_received']\n",
    "y_test = test['insurance_benefits_received']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "knn.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.40\n",
      "Confusion Matrix\n",
      "[[1310   21]\n",
      " [ 122   47]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate metrics\n",
    "eval_classifier(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score and confusion matrix for k: 1\n",
      "F1: 0.59\n",
      "Confusion Matrix\n",
      "[[1309   22]\n",
      " [  90   79]]\n",
      "\n",
      "F1 score and confusion matrix for k: 2\n",
      "F1: 0.39\n",
      "Confusion Matrix\n",
      "[[1324    7]\n",
      " [ 126   43]]\n",
      "\n",
      "F1 score and confusion matrix for k: 3\n",
      "F1: 0.40\n",
      "Confusion Matrix\n",
      "[[1310   21]\n",
      " [ 122   47]]\n",
      "\n",
      "F1 score and confusion matrix for k: 4\n",
      "F1: 0.16\n",
      "Confusion Matrix\n",
      "[[1325    6]\n",
      " [ 154   15]]\n",
      "\n",
      "F1 score and confusion matrix for k: 5\n",
      "F1: 0.15\n",
      "Confusion Matrix\n",
      "[[1320   11]\n",
      " [ 154   15]]\n",
      "\n",
      "F1 score and confusion matrix for k: 6\n",
      "F1: 0.06\n",
      "Confusion Matrix\n",
      "[[1331    0]\n",
      " [ 164    5]]\n",
      "\n",
      "F1 score and confusion matrix for k: 7\n",
      "F1: 0.07\n",
      "Confusion Matrix\n",
      "[[1330    1]\n",
      " [ 163    6]]\n",
      "\n",
      "F1 score and confusion matrix for k: 8\n",
      "F1: 0.05\n",
      "Confusion Matrix\n",
      "[[1331    0]\n",
      " [ 165    4]]\n",
      "\n",
      "F1 score and confusion matrix for k: 9\n",
      "F1: 0.05\n",
      "Confusion Matrix\n",
      "[[1331    0]\n",
      " [ 165    4]]\n",
      "\n",
      "F1 score and confusion matrix for k: 10\n",
      "F1: 0.00\n",
      "Confusion Matrix\n",
      "[[1331    0]\n",
      " [ 169    0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# model performance using unscaled data and k from 1 to 10\n",
    "k = np.arange(1, 11)\n",
    "for k in k:\n",
    "    print('F1 score and confusion matrix for k:', k)\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k) \n",
    "    knn.fit(X_train, y_train)\n",
    "    knn.predict(X_test)\n",
    "    eval_classifier(y_test, knn.predict(X_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see here that *k* has an influence on evaluation metrics.\n",
    "    - the higher *k* is, the lower F1 score is.\n",
    "- The highest value of F1 score is obtained on *k* = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure F1 metric on scaled data using KNN-based classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>insurance_benefits_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.265823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.527848</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.330380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender       age    income  family_members  insurance_benefits  \\\n",
       "0     1.0  0.630769  0.627848        0.166667                   0   \n",
       "1     0.0  0.707692  0.481013        0.166667                   1   \n",
       "2     0.0  0.446154  0.265823        0.000000                   0   \n",
       "3     0.0  0.323077  0.527848        0.333333                   0   \n",
       "4     1.0  0.430769  0.330380        0.000000                   0   \n",
       "\n",
       "   insurance_benefits_received  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate target for scaled data\n",
    "df_scaled['insurance_benefits_received'] = (df_scaled['insurance_benefits'] > 0).astype(int)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and traget for unscaled data\n",
    "X = df[feature_names]\n",
    "y = df['insurance_benefits_received']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce only feature columns for scaled data\n",
    "X_scaled = df_scaled[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled = train_test_split(\n",
    "    X, y, X_scaled, test_size = 0.3, random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score and confusion matrix for k: 1\n",
      "F1: 0.97\n",
      "Confusion Matrix\n",
      "[[1333    4]\n",
      " [   7  156]]\n",
      "\n",
      "F1 score and confusion matrix for k: 2\n",
      "F1: 0.93\n",
      "Confusion Matrix\n",
      "[[1336    1]\n",
      " [  21  142]]\n",
      "\n",
      "F1 score and confusion matrix for k: 3\n",
      "F1: 0.95\n",
      "Confusion Matrix\n",
      "[[1334    3]\n",
      " [  13  150]]\n",
      "\n",
      "F1 score and confusion matrix for k: 4\n",
      "F1: 0.91\n",
      "Confusion Matrix\n",
      "[[1334    3]\n",
      " [  25  138]]\n",
      "\n",
      "F1 score and confusion matrix for k: 5\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1330    7]\n",
      " [  17  146]]\n",
      "\n",
      "F1 score and confusion matrix for k: 6\n",
      "F1: 0.90\n",
      "Confusion Matrix\n",
      "[[1335    2]\n",
      " [  27  136]]\n",
      "\n",
      "F1 score and confusion matrix for k: 7\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1331    6]\n",
      " [  19  144]]\n",
      "\n",
      "F1 score and confusion matrix for k: 8\n",
      "F1: 0.90\n",
      "Confusion Matrix\n",
      "[[1333    4]\n",
      " [  26  137]]\n",
      "\n",
      "F1 score and confusion matrix for k: 9\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1333    4]\n",
      " [  22  141]]\n",
      "\n",
      "F1 score and confusion matrix for k: 10\n",
      "F1: 0.88\n",
      "Confusion Matrix\n",
      "[[1333    4]\n",
      " [  32  131]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model performance using scaled data and k from 1 to 10\n",
    "k = np.arange(1, 11)\n",
    "for k in k:\n",
    "    print('F1 score and confusion matrix for k:', k)\n",
    "    model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    eval_classifier(y_test, y_pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see here, with a scaled data, that F1 slightly decreased by inscreasing *k*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The probability of paying any insurance benefit is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability: 0.00\n",
      "F1: 0.00\n",
      "Confusion Matrix\n",
      "[[1337    0]\n",
      " [ 163    0]]\n",
      "\n",
      "The probability: 0.11\n",
      "F1: 0.11\n",
      "Confusion Matrix\n",
      "[[1180  157]\n",
      " [ 144   19]]\n",
      "\n",
      "The probability: 0.50\n",
      "F1: 0.16\n",
      "Confusion Matrix\n",
      "[[668 669]\n",
      " [ 90  73]]\n",
      "\n",
      "The probability: 1.00\n",
      "F1: 0.20\n",
      "Confusion Matrix\n",
      "[[   0 1337]\n",
      " [   0  163]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'The probability: {P:.2f}')\n",
    "    y_pred_rnd =  rnd_model_predict(P, y_test.shape[0]) # <your code here> \n",
    "        \n",
    "    eval_classifier(y_test, y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model is giving a highest score at p = 1 with F1 = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myclassifier\n",
    "class MyClassifier():\n",
    "    def __init__(self, n_neighbors, metric='euclidean', threshold = 0.5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        self.nn = sklearn.neighbors.NearestNeighbors(n_neighbors=n_neighbors, metric=metric)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.features = X\n",
    "        self.target = y\n",
    "        self.nn.fit(self.features)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        nbrs_distances, nbrs_indices = self.nn.kneighbors(X, self.n_neighbors, return_distance=True)\n",
    "        probabilities = []\n",
    "        for elem in nbrs_indices:\n",
    "            probability = self.target.iloc[elem].mean()\n",
    "            probabilities.append(probability)\n",
    "        return (np.array(probabilities) >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyClassifier(n_neighbors = 3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X_test) != knn.predict(X_test)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- For unscaled data: k has an influence in evalution metrics. When k is high, F1 is low.\n",
    "- For scaled data: k influence slightly F1 score, the higher k is the lower F1 is. And we also obtained higher values of F1 score.\n",
    "- The dummy gave a highest score at p = 1 with F1 = 0.20, and we can say that all customers will benefit from the insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Great, you successfully applied knn to a classification problem. As you confirmed, scaling greatly influences the quality of distance-based models like knn.\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4\"> Task 3. Regression (with Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `insurance_benefits` as the target, evaluate what RMSE would be for a Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own implementation of LR. For that, recall how the linear regression task's solution is formulated in terms of LA. Check RMSE for both the original data and the scaled one. Can you see any difference in RMSE between these two cases?\n",
    "\n",
    "Let's denote\n",
    "- $X$  feature matrix, each row is a case, each column is a feature, the first column consists of unities\n",
    "- $y$  target (a vector)\n",
    "- $\\hat{y}$  estimated tagret (a vector)\n",
    "- $w$  weight vector\n",
    "\n",
    "The task of linear regression in the language of matrices can be formulated as\n",
    "\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "The training objective then is to find such $w$ that it would minimize the L2-distance (MSE) between $Xw$ and $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "It appears that there is analytical solution for the above:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "The formula above can be used to find the weights $w$ and the latter can be used to calculate predicted values\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the whole data in the 70:30 proportion for the training/validation parts. Use the RMSE metric for the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # adding the unities\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        self.weights = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)\n",
    "        # <your code here>\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # adding the unities\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        y_pred = X2.dot(self.weights)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Linear regression was implemented correctly!\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression for original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.43539012e-01  3.57495491e-02  1.64272726e-02 -2.60743659e-07\n",
      " -1.16902127e-02]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression for scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94353901  2.32372069  0.01642727 -0.02059875 -0.07014128]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X = df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df_scaled['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- We can see that, comparing the RMSE and R2 score between scaled and unscaled data, the evaluation metric still gave the same result. \n",
    "- The difference we can see is in the weights of the models. On scaled data, the model trained is more interpretable than the unscaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Well done!\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"5\"> Task 4. Obfuscating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It best to obfuscate data by multiplying the numerical features (remember, they can be seen as the matrix $X$) by an invertible matrix $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Try to do that and check how the features' values will look like after the transformation. By the way, the intertible property is important here so make sure that $P$ is indeed invertible.\n",
    "\n",
    "You may want to review the 'Matrices and Matrix Operations -> Matrix Mupliplication' lesson to recall the rule of matrix multiplication and its implementation with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 4.10e+01, 4.96e+04, 1.00e+00],\n",
       "       [0.00e+00, 4.60e+01, 3.80e+04, 1.00e+00],\n",
       "       [0.00e+00, 2.90e+01, 2.10e+04, 0.00e+00],\n",
       "       ...,\n",
       "       [0.00e+00, 2.00e+01, 3.39e+04, 2.00e+00],\n",
       "       [1.00e+00, 2.20e+01, 3.27e+04, 3.00e+00],\n",
       "       [1.00e+00, 2.80e+01, 4.06e+04, 1.00e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a random matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the matrix $P$ is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77395605, 0.43887844, 0.85859792, 0.69736803],\n",
       "       [0.09417735, 0.97562235, 0.7611397 , 0.78606431],\n",
       "       [0.12811363, 0.45038594, 0.37079802, 0.92676499],\n",
       "       [0.64386512, 0.82276161, 0.4434142 , 0.22723872]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.85130588e-16, -2.97856902e-16,\n",
       "        -3.91584367e-17],\n",
       "       [ 6.23834470e-17,  1.00000000e+00, -7.10568689e-17,\n",
       "         8.24459807e-17],\n",
       "       [ 1.03941594e-17,  2.27454503e-17,  1.00000000e+00,\n",
       "        -5.77784356e-17],\n",
       "       [-1.02697151e-16, -1.69379178e-16, -2.49945035e-17,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(P, np.linalg.inv(P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see here that P is invertible since we have Ones in the diagonal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess the customers' ages or income after the transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6359.71527314, 22380.40467609, 18424.09074184, 46000.69669016],\n",
       "       [ 4873.29406479, 17160.36702982, 14125.78076133, 35253.45577301],\n",
       "       [ 2693.11742928,  9486.397744  ,  7808.83156024, 19484.86063067],\n",
       "       ...,\n",
       "       [ 4346.2234249 , 15289.24126492, 12586.16264392, 31433.50888552],\n",
       "       [ 4194.09324155, 14751.9910242 , 12144.02930637, 30323.88763426],\n",
       "       [ 5205.46827354, 18314.24814446, 15077.01370762, 37649.59295455]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prime = np.matmul(X, P)\n",
    "X_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you recover the original data from $X'$ if you know $P$? Try to check that with calculations by moving $P$ from the right side of the formula above to the left one. The rules of matrix multiplcation are really helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [ 1.67952800e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-6.23021448e-13,  2.90000000e+01,  2.10000000e+04,\n",
       "        -2.03032656e-13],\n",
       "       ...,\n",
       "       [ 1.57996161e-12,  2.00000000e+01,  3.39000000e+04,\n",
       "         2.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.20000000e+01,  3.27000000e+04,\n",
       "         3.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.80000000e+01,  4.06000000e+04,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rec = X_prime.dot(np.linalg.inv(P))\n",
    "X_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all three cases for a few customers\n",
    "- The original data\n",
    "- The transformed one\n",
    "- The reversed (recovered) one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data \n",
      " [[1.00e+00 4.10e+01 4.96e+04 1.00e+00]\n",
      " [0.00e+00 4.60e+01 3.80e+04 1.00e+00]\n",
      " [0.00e+00 2.90e+01 2.10e+04 0.00e+00]]\n",
      "\n",
      "Transformed data \n",
      " [[ 6359.71527314 22380.40467609 18424.09074184 46000.69669016]\n",
      " [ 4873.29406479 17160.36702982 14125.78076133 35253.45577301]\n",
      " [ 2693.11742928  9486.397744    7808.83156024 19484.86063067]]\n",
      "\n",
      "Reversed (recovered) data \n",
      " [[ 1.00000000e+00  4.10000000e+01  4.96000000e+04  1.00000000e+00]\n",
      " [ 1.67952800e-12  4.60000000e+01  3.80000000e+04  1.00000000e+00]\n",
      " [-6.23021448e-13  2.90000000e+01  2.10000000e+04 -2.03032656e-13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original data \\n {}'.format(X[:3]))\n",
    "print()\n",
    "print('Transformed data \\n {}'.format(X_prime[:3]))\n",
    "print()\n",
    "print('Reversed (recovered) data \\n {}'.format(X_rec[:3]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably see that some values are not exactly the same as they are in the original data. What might be the reason for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This might be due to the precision of the numpy s calculation when data is close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Yep, that's pretty much it! You successfully tried obfuscating the data and recovering the original data using an inverse matrix.\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof That Data Obfuscation Can Work with LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression task has been solved with linear regression in this project. Your next task is to prove _analytically_ that the given obfuscation method won't affect linear regression in terms of predicted values i.e. their values will remain the same. Can you believe that? Well, you don't have to, you should prove it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the data is obfuscated and there is $X \\times P$ instead of just $X$ now. Consequently, there are other weights $w_P$ as\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "How would $w$ and $w_P$ be linked if you simplify the formula for $w_P$ above? \n",
    "\n",
    "What would be predicted values with $w_P$? \n",
    "\n",
    "What does that mean for the quality of linear regression if you measure it with RMSE?\n",
    "\n",
    "Check Appendix B Properties of Matrices in the end of the notebook. There are useful formulas in there!\n",
    "\n",
    "No code is necessary in this section, only analytical explanation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical proof**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = [(XP)^T XP]^{-1}(XP)^Ty \\qquad \\qquad $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expand $(XP)^T$ using reversivity of transpose property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = [P^T X^T XP]^{-1} P^T X^T y\\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aranging square brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = (P^T (X^T X) P)^{-1} P^T X^T y \\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- expand the bracket $(P^T (X^T X) P)^{-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = P^{-1} (X^T X)^{-1} (P^T)^{-1} P^T X^T y \\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since $(P^T)^{-1} P^T = P^T (P^T)^{-1}  = I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = P^{-1} (X^T X)^{-1} I X^T y \\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- applying identity property for multiplication $ I X^T = X^T I = X^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = P^{-1} (X^T X)^{-1} X^T y \\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- subtituting $w = (X^T X)^{-1} X^T y$ into the previous equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_p = P^{-1} w \\qquad \\qquad$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would be predicted values with  $w_p$ ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a = Xw$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a' = X'w_p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X' = XP$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and$$w_p = P^{-1}w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- by substituting these values into $a'$ we will have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "    a'= XP.P^{-1}w = XIw \\\\\n",
    "    \\therefore a'= Xw = a\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does that mean for the quality of linear regression if you measure it with RMSE?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have $a'$ and $a$ are the same, so the RMSE calculated for both the transformed and non transformed dataset will remain the same.\n",
    "- And the quality of linear regression measured with RMSE will be similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "  \n",
    "Great, the proof is correct. \n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "  \n",
    "This task is missing. Basically, you just need to simplify the expresion for $w_p$ using the formulas from the appendix (keep in mind that $X$ is not invertible, but $X^T X$ is, so you've got to be careful not to use $X^{-1}$ in your proof), then use it to find the predictions of the new model and compare them to the old predictions. If you have trouble with this task, I suggest contacting the tutor (if you don't know how, ask the community manager).\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Linear Regression With Data Obfuscation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prove Linear Regression can work computationally with the chosen obfuscation transformation.\n",
    "\n",
    "Build a procedure or a class that runs Linear Regression optionally with the obfuscation. You can use either a ready implementation of Linear Regression from sciki-learn or your own.\n",
    "\n",
    "Run Linear Regression for the original data and the obfuscated one, compare the predicted values and the RMSE, $R^2$ metric values. Is there any difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**\n",
    "\n",
    "- Create a square matrix $P$ of random numbers.\n",
    "- Check that it is invertible. If not, repeat the first point until we get an invertible matrix.\n",
    "- <! your comment here !>\n",
    "- Use $XP$ as the new feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = np.random.default_rng(seed=42)\n",
    "P = rn.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77395605, 0.43887844, 0.85859792, 0.69736803],\n",
       "       [0.09417735, 0.97562235, 0.7611397 , 0.78606431],\n",
       "       [0.12811363, 0.45038594, 0.37079802, 0.92676499],\n",
       "       [0.64386512, 0.82276161, 0.4434142 , 0.22723872]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is matrix P invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.85130588e-16, -2.97856902e-16,\n",
       "        -3.91584367e-17],\n",
       "       [ 6.23834470e-17,  1.00000000e+00, -7.10568689e-17,\n",
       "         8.24459807e-17],\n",
       "       [ 1.03941594e-17,  2.27454503e-17,  1.00000000e+00,\n",
       "        -5.77784356e-17],\n",
       "       [-1.02697151e-16, -1.69379178e-16, -2.49945035e-17,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(P, np.linalg.inv(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = df[\"insurance_benefits\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LR on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.43539012e-01  1.64272726e-02  3.57495491e-02 -2.60743659e-07\n",
      " -1.16902127e-02]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LR on obfuscated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94353901 -0.05791721 -0.01546567  0.09871889 -0.02397536]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_prime = X.dot(P)\n",
    "\n",
    "X_train_obs, X_test_obs, y_train_obs, y_test_obs = train_test_split(X_prime, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train_obs, y_train_obs)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test_obs)\n",
    "eval_regressor(y_test_obs, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using computational means, we obtained similar RMSE of 0.34 and $R^2$ score of 0.66 for both original and obfuscated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Great, you successfully experimentally confirmed that data obfuscation doesn't impact model's quality \n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\"> Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business task of this project is data masking for the Sure Tomorrow insurance, by developing a data transformation algorithm that would make it hard to recover personal information if the data fell into the wrong hands.\n",
    "1. First step, data discovery\n",
    "    - we loaded the data that consists of 5000 rows and 5 columns. \n",
    "    - We renamed the columns and changed data type for the age feature from float to int. \n",
    "    - we've seen that there are no missing values in the data. \n",
    "    - \n",
    "2. EDA\n",
    "    - We performed exploratory data analysis on the data and determined if scaling is affecting the kNN algorithm.\n",
    "    - The unscaled data affects the kNN algorithm because the algorithm is giving more importance features with higher ranging numbers. \n",
    "    - using euclidean distance, for unscaled data, the distance metric calculated ranges from 0.00 to 5.09, whereas for scaled data, the distance metric range of 0.00 to 0.03. \n",
    "    - This shows the impact of data scaling. With data scaling, the distances are more comparable than with unscaled data.\n",
    "3. We built a custom kNN classifier\n",
    "    - we measured the quality \n",
    "        - F1 metric for k=1 to 10 for both the original data and the scaled one. \n",
    "    - we observed that for the original and unscaled data, k influences the evaluation metric. The higher the value of k the lower the F1 score recorded. \n",
    "    - The dummy model gave the highest F1-score of 0.2 at a probability value of 1. This model predicted that all customers will benefit from the insurance.\n",
    "4. LR implementation\n",
    "    - we imlemented and calculated RMSE and R2 score or both the original and the scaled data.\n",
    "    - we've seen no difference in RMSE and $R^2$ score between these two.\n",
    "5. Data obfuscated\n",
    "    - we've proved analytically that obfuscation is working with LR\n",
    "    - when testing the linear regression with data obfuscation, we obtained similar RMSE value of 0.34 and $R^2$ score of 0.66, for both the original and obfuscated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "  \n",
    "Ok!\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells are arranged in order of logic and execution\n",
    "- [ ]  Task 1 has been performed\n",
    "    - [ ]  There is the procedure that can return k similar customers for a given one\n",
    "    - [ ]  The procedure is tested for all four proposed combinations\n",
    "    - [ ]  The questions re the scaling/distances are answered\n",
    "- [ ]  Task 2 has been performed\n",
    "    - [ ]  The random classification model is built and tested for all for probability levels\n",
    "    - [ ]  The kNN classification model is built and tested for both the original data and the scaled one, the F1 metric is calculated.\n",
    "- [ ]  Task 3 has been performed\n",
    "    - [ ]  The linear tegression solution is implemented with matrix operations.\n",
    "    - [ ]  RMSE is calculated for the implemented solution.\n",
    "- [ ]  Task 4 has been performed\n",
    "    - [ ]  The data is obfuscated with a random and invertible matrix P\n",
    "    - [ ]  The obfuscated data is recoved, few examples are printed out\n",
    "    - [ ]  The analytical proof that the transformation does not affect RMSE is provided \n",
    "    - [ ]  The computational proof that the transformation does not affect RMSE is provided\n",
    "- [ ]  Conclusions have been made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices \n",
    "\n",
    "## Appendix A: Writing Formulas in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write formulas in your Jupyter Notebook in a markup language provided by a high-quality publishing system called $\\LaTeX$ (pronounced \"Lah-tech\"), and they will look like formulas in textbooks.\n",
    "\n",
    "To put a formula in a text, put the dollar sign (\\\\$) before and after the formula's text e.g. $\\frac{1}{2} \\times \\frac{3}{2} = \\frac{3}{4}$ or $y = x^2, x \\ge 1$.\n",
    "\n",
    "If a formula should be in its own paragraph, put the double dollar sign (\\\\$\\\\$) before and after the formula text e.g.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.\n",
    "$$\n",
    "\n",
    "The markup language of [LaTeX](https://en.wikipedia.org/wiki/LaTeX) is very popular among people who use formulas in their articles, books and texts. It can be complex but its basics are easy. Check this two page [cheatsheet](http://tug.ctan.org/info/undergradmath/undergradmath.pdf) for learning how to compose the most common formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B: Properties of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices have many properties in Linear Algebra. A few of them are listed here which can help with the analytical proof in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>Distributivity</td><td>$A(B+C)=AB+AC$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Non-commutativity</td><td>$AB \\neq BA$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Associative property of multiplication</td><td>$(AB)C = A(BC)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Multiplicative identity property</td><td>$IA = AI = A$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td></td><td>$A^{-1}A = AA^{-1} = I$\n",
    "</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td></td><td>$(AB)^{-1} = B^{-1}A^{-1}$</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td>Reversivity of the transpose of a product of matrices,</td><td>$(AB)^T = B^TA^T$</td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1623,
    "start_time": "2021-09-12T14:11:18.863Z"
   },
   {
    "duration": 2818,
    "start_time": "2021-09-12T14:12:04.983Z"
   },
   {
    "duration": 138,
    "start_time": "2021-09-12T14:12:33.006Z"
   },
   {
    "duration": 20,
    "start_time": "2021-09-12T14:12:48.155Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-12T14:13:08.527Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-12T14:13:26.173Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-12T14:13:29.527Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-12T14:13:31.962Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-12T14:13:47.253Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-12T14:14:10.865Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-12T14:14:36.441Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-12T14:16:33.674Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-12T14:17:26.653Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-12T14:17:41.233Z"
   },
   {
    "duration": 8492,
    "start_time": "2021-09-12T14:21:50.619Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-12T14:24:40.409Z"
   },
   {
    "duration": 8795,
    "start_time": "2021-09-12T14:27:41.695Z"
   },
   {
    "duration": 8305,
    "start_time": "2021-09-12T14:46:15.878Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-12T14:56:59.150Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-12T14:58:10.277Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-12T14:58:54.983Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-12T14:59:48.769Z"
   },
   {
    "duration": 1176,
    "start_time": "2021-09-13T13:45:55.588Z"
   },
   {
    "duration": 103,
    "start_time": "2021-09-13T13:46:00.838Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-13T13:46:04.110Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-13T13:47:29.877Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-13T14:23:33.951Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-13T15:47:20.416Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-13T15:47:23.747Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-13T15:47:27.684Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-13T15:48:37.953Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-13T15:48:56.138Z"
   },
   {
    "duration": 4870,
    "start_time": "2021-09-13T15:49:01.543Z"
   },
   {
    "duration": 2,
    "start_time": "2021-09-13T16:49:24.237Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-13T16:49:26.287Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-13T16:57:02.749Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-13T16:57:07.388Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-13T16:57:36.980Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-13T16:58:02.493Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-13T16:58:35.552Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-13T17:13:46.077Z"
   },
   {
    "duration": 1159,
    "start_time": "2021-09-13T17:38:18.193Z"
   },
   {
    "duration": 112,
    "start_time": "2021-09-13T17:38:22.491Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-13T17:38:25.365Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-13T17:38:28.443Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-13T17:38:31.760Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T17:38:34.513Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-13T17:38:36.837Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-13T17:38:39.936Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-13T17:38:43.170Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-13T17:38:50.312Z"
   },
   {
    "duration": 4622,
    "start_time": "2021-09-13T17:38:53.654Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T17:39:07.470Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-13T17:39:09.632Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-13T17:39:12.374Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-13T17:39:15.712Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-13T17:39:19.463Z"
   },
   {
    "duration": 24,
    "start_time": "2021-09-13T17:39:23.484Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-13T17:39:26.885Z"
   },
   {
    "duration": 24,
    "start_time": "2021-09-13T17:39:31.090Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-13T18:00:51.259Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-13T18:10:31.968Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T18:19:41.770Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T18:19:50.955Z"
   },
   {
    "duration": 81,
    "start_time": "2021-09-13T18:20:06.073Z"
   },
   {
    "duration": 370,
    "start_time": "2021-09-13T18:23:13.514Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-13T18:24:13.439Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-13T18:24:25.571Z"
   },
   {
    "duration": 40,
    "start_time": "2021-09-13T18:25:00.218Z"
   },
   {
    "duration": 510,
    "start_time": "2021-09-13T18:25:15.983Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T18:26:19.075Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-13T18:26:20.892Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-13T18:26:23.612Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-13T18:26:25.633Z"
   },
   {
    "duration": 39,
    "start_time": "2021-09-13T18:26:28.894Z"
   },
   {
    "duration": 42,
    "start_time": "2021-09-13T18:26:31.200Z"
   },
   {
    "duration": 750,
    "start_time": "2021-09-13T18:26:48.218Z"
   },
   {
    "duration": 1516,
    "start_time": "2021-09-14T21:55:07.961Z"
   },
   {
    "duration": 144,
    "start_time": "2021-09-14T21:55:14.286Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-14T21:55:35.704Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-14T21:55:39.523Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-14T21:55:43.171Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-14T21:55:46.340Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-14T21:55:51.166Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-14T21:55:55.032Z"
   },
   {
    "duration": 1564,
    "start_time": "2021-09-15T16:09:33.870Z"
   },
   {
    "duration": 115,
    "start_time": "2021-09-15T16:09:42.544Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T16:09:47.547Z"
   },
   {
    "duration": 20,
    "start_time": "2021-09-15T16:09:51.376Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T16:10:01.464Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T16:10:03.885Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T16:10:13.141Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-15T16:10:13.315Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-15T16:10:30.160Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-15T16:10:54.060Z"
   },
   {
    "duration": 8547,
    "start_time": "2021-09-15T16:10:57.243Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-15T16:13:28.522Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T16:30:18.020Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-15T16:30:21.860Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T16:30:24.492Z"
   },
   {
    "duration": 24,
    "start_time": "2021-09-15T16:30:27.208Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-15T16:30:30.210Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-15T16:30:33.224Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-15T16:30:36.381Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T16:30:40.892Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T16:30:43.724Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T16:30:45.555Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T16:30:47.596Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T16:42:14.276Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-15T16:42:16.487Z"
   },
   {
    "duration": 108,
    "start_time": "2021-09-15T16:42:19.576Z"
   },
   {
    "duration": 97,
    "start_time": "2021-09-15T16:42:21.723Z"
   },
   {
    "duration": 1591,
    "start_time": "2021-09-15T16:42:23.820Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-15T16:56:51.011Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T18:17:38.339Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T18:17:50.167Z"
   },
   {
    "duration": 572,
    "start_time": "2021-09-15T18:20:06.878Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T18:53:16.931Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T18:53:18.780Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T18:53:20.406Z"
   },
   {
    "duration": 979,
    "start_time": "2021-09-15T18:53:30.386Z"
   },
   {
    "duration": 31,
    "start_time": "2021-09-15T18:59:19.872Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:31:23.886Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-15T20:31:56.528Z"
   },
   {
    "duration": 457,
    "start_time": "2021-09-15T20:32:57.653Z"
   },
   {
    "duration": 80,
    "start_time": "2021-09-15T20:33:12.508Z"
   },
   {
    "duration": 615,
    "start_time": "2021-09-15T20:33:28.391Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:35:42.514Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:35:50.520Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-15T20:36:26.664Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:37:07.875Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T20:37:53.925Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-15T20:38:13.924Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:38:26.079Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:38:38.083Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:38:48.948Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:39:03.961Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:40:29.108Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-15T20:40:45.255Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:42:38.786Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:42:54.069Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:43:08.028Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:45:06.945Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:45:15.489Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:46:09.692Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:46:30.545Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:46:41.910Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:50:00.264Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-15T20:54:35.349Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:55:08.779Z"
   },
   {
    "duration": 1582,
    "start_time": "2021-09-15T20:57:56.590Z"
   },
   {
    "duration": 152,
    "start_time": "2021-09-15T20:57:58.175Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T20:57:58.329Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-15T20:57:58.337Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-15T20:57:58.358Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:57:58.369Z"
   },
   {
    "duration": 46,
    "start_time": "2021-09-15T20:57:58.378Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-15T20:57:58.427Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-15T20:57:58.467Z"
   },
   {
    "duration": 41,
    "start_time": "2021-09-15T20:57:58.480Z"
   },
   {
    "duration": 8420,
    "start_time": "2021-09-15T20:57:58.523Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-15T20:58:06.945Z"
   },
   {
    "duration": 31,
    "start_time": "2021-09-15T20:58:06.952Z"
   },
   {
    "duration": 27,
    "start_time": "2021-09-15T20:58:06.986Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:58:07.016Z"
   },
   {
    "duration": 26,
    "start_time": "2021-09-15T20:58:07.032Z"
   },
   {
    "duration": 66,
    "start_time": "2021-09-15T20:58:07.061Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-15T20:58:07.130Z"
   },
   {
    "duration": 61,
    "start_time": "2021-09-15T20:58:07.155Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:58:07.219Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-15T20:58:07.228Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-15T20:58:07.249Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:58:07.270Z"
   },
   {
    "duration": 62,
    "start_time": "2021-09-15T20:58:07.282Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-15T20:58:07.347Z"
   },
   {
    "duration": 126,
    "start_time": "2021-09-15T20:58:07.364Z"
   },
   {
    "duration": 136,
    "start_time": "2021-09-15T20:58:07.493Z"
   },
   {
    "duration": 1507,
    "start_time": "2021-09-15T20:58:07.632Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:58:09.141Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:58:09.158Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:58:09.168Z"
   },
   {
    "duration": 676,
    "start_time": "2021-09-15T20:58:09.179Z"
   },
   {
    "duration": -194,
    "start_time": "2021-09-15T20:58:10.052Z"
   },
   {
    "duration": -213,
    "start_time": "2021-09-15T20:58:10.072Z"
   },
   {
    "duration": -219,
    "start_time": "2021-09-15T20:58:10.080Z"
   },
   {
    "duration": -224,
    "start_time": "2021-09-15T20:58:10.086Z"
   },
   {
    "duration": -231,
    "start_time": "2021-09-15T20:58:10.094Z"
   },
   {
    "duration": -259,
    "start_time": "2021-09-15T20:58:10.124Z"
   },
   {
    "duration": -275,
    "start_time": "2021-09-15T20:58:10.142Z"
   },
   {
    "duration": -281,
    "start_time": "2021-09-15T20:58:10.149Z"
   },
   {
    "duration": -287,
    "start_time": "2021-09-15T20:58:10.156Z"
   },
   {
    "duration": -290,
    "start_time": "2021-09-15T20:58:10.161Z"
   },
   {
    "duration": -295,
    "start_time": "2021-09-15T20:58:10.167Z"
   },
   {
    "duration": -299,
    "start_time": "2021-09-15T20:58:10.173Z"
   },
   {
    "duration": -306,
    "start_time": "2021-09-15T20:58:10.181Z"
   },
   {
    "duration": -309,
    "start_time": "2021-09-15T20:58:10.186Z"
   },
   {
    "duration": -315,
    "start_time": "2021-09-15T20:58:10.194Z"
   },
   {
    "duration": -319,
    "start_time": "2021-09-15T20:58:10.200Z"
   },
   {
    "duration": -325,
    "start_time": "2021-09-15T20:58:10.207Z"
   },
   {
    "duration": -329,
    "start_time": "2021-09-15T20:58:10.213Z"
   },
   {
    "duration": -333,
    "start_time": "2021-09-15T20:58:10.219Z"
   },
   {
    "duration": -350,
    "start_time": "2021-09-15T20:58:10.237Z"
   },
   {
    "duration": -446,
    "start_time": "2021-09-15T20:58:10.335Z"
   },
   {
    "duration": -477,
    "start_time": "2021-09-15T20:58:10.367Z"
   },
   {
    "duration": -482,
    "start_time": "2021-09-15T20:58:10.374Z"
   },
   {
    "duration": -487,
    "start_time": "2021-09-15T20:58:10.380Z"
   },
   {
    "duration": -493,
    "start_time": "2021-09-15T20:58:10.388Z"
   },
   {
    "duration": -498,
    "start_time": "2021-09-15T20:58:10.394Z"
   },
   {
    "duration": -485,
    "start_time": "2021-09-15T20:58:10.400Z"
   },
   {
    "duration": -489,
    "start_time": "2021-09-15T20:58:10.405Z"
   },
   {
    "duration": 1506,
    "start_time": "2021-09-15T20:59:11.060Z"
   },
   {
    "duration": 96,
    "start_time": "2021-09-15T20:59:12.569Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:59:12.668Z"
   },
   {
    "duration": 25,
    "start_time": "2021-09-15T20:59:12.676Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:59:12.704Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:59:12.715Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-15T20:59:12.725Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-15T20:59:12.745Z"
   },
   {
    "duration": 40,
    "start_time": "2021-09-15T20:59:12.783Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-15T20:59:12.826Z"
   },
   {
    "duration": 8161,
    "start_time": "2021-09-15T20:59:12.840Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:59:21.003Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-15T20:59:21.019Z"
   },
   {
    "duration": 25,
    "start_time": "2021-09-15T20:59:21.035Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:59:21.062Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-15T20:59:21.078Z"
   },
   {
    "duration": 34,
    "start_time": "2021-09-15T20:59:21.103Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-15T20:59:21.139Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-15T20:59:21.162Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T20:59:21.201Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-15T20:59:21.208Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-15T20:59:21.223Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T20:59:21.235Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-15T20:59:21.243Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-15T20:59:21.262Z"
   },
   {
    "duration": 89,
    "start_time": "2021-09-15T20:59:21.274Z"
   },
   {
    "duration": 77,
    "start_time": "2021-09-15T20:59:21.366Z"
   },
   {
    "duration": 1795,
    "start_time": "2021-09-15T20:59:21.445Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-15T20:59:23.242Z"
   },
   {
    "duration": 59,
    "start_time": "2021-09-15T20:59:23.261Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:59:23.323Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-15T20:59:23.332Z"
   },
   {
    "duration": 989,
    "start_time": "2021-09-15T20:59:23.349Z"
   },
   {
    "duration": 31,
    "start_time": "2021-09-15T20:59:24.341Z"
   },
   {
    "duration": 43,
    "start_time": "2021-09-15T20:59:24.375Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-15T20:59:24.421Z"
   },
   {
    "duration": 525,
    "start_time": "2021-09-15T20:59:24.434Z"
   },
   {
    "duration": 112,
    "start_time": "2021-09-15T20:59:24.962Z"
   },
   {
    "duration": 548,
    "start_time": "2021-09-15T20:59:25.077Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:59:25.628Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-15T20:59:25.640Z"
   },
   {
    "duration": 73,
    "start_time": "2021-09-15T20:59:25.653Z"
   },
   {
    "duration": 96,
    "start_time": "2021-09-15T20:59:25.730Z"
   },
   {
    "duration": 88,
    "start_time": "2021-09-15T20:59:25.830Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:59:25.922Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-15T20:59:26.016Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:59:26.028Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-15T20:59:26.039Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:59:26.050Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-15T20:59:26.116Z"
   },
   {
    "duration": 91,
    "start_time": "2021-09-15T20:59:26.125Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-15T20:59:26.219Z"
   },
   {
    "duration": 90,
    "start_time": "2021-09-15T20:59:26.230Z"
   },
   {
    "duration": 19,
    "start_time": "2021-09-15T20:59:26.323Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-15T20:59:26.345Z"
   },
   {
    "duration": 56,
    "start_time": "2021-09-15T20:59:26.364Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-15T20:59:26.423Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-15T20:59:26.516Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-15T20:59:26.524Z"
   },
   {
    "duration": 82,
    "start_time": "2021-09-15T20:59:26.548Z"
   },
   {
    "duration": 1735,
    "start_time": "2021-09-16T15:53:15.350Z"
   },
   {
    "duration": 102,
    "start_time": "2021-09-16T15:53:17.088Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-16T15:53:17.193Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-16T15:53:17.204Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-16T15:53:17.228Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-16T15:53:17.240Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-16T15:53:17.268Z"
   },
   {
    "duration": 34,
    "start_time": "2021-09-16T15:53:17.283Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-16T15:53:17.320Z"
   },
   {
    "duration": 34,
    "start_time": "2021-09-16T15:53:17.334Z"
   },
   {
    "duration": 8574,
    "start_time": "2021-09-16T15:53:17.371Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-16T15:53:25.947Z"
   },
   {
    "duration": 24,
    "start_time": "2021-09-16T15:53:25.952Z"
   },
   {
    "duration": 29,
    "start_time": "2021-09-16T15:53:25.978Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-16T15:53:26.010Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-16T15:53:26.034Z"
   },
   {
    "duration": 40,
    "start_time": "2021-09-16T15:53:26.073Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-16T15:53:26.115Z"
   },
   {
    "duration": 58,
    "start_time": "2021-09-16T15:53:26.141Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-16T15:53:26.201Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-16T15:53:26.211Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-16T15:53:26.232Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-16T15:53:26.270Z"
   },
   {
    "duration": 27,
    "start_time": "2021-09-16T15:53:26.278Z"
   },
   {
    "duration": 26,
    "start_time": "2021-09-16T15:53:26.307Z"
   },
   {
    "duration": 93,
    "start_time": "2021-09-16T15:53:26.336Z"
   },
   {
    "duration": 87,
    "start_time": "2021-09-16T15:53:26.432Z"
   },
   {
    "duration": 1471,
    "start_time": "2021-09-16T15:53:26.521Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-16T15:53:27.995Z"
   },
   {
    "duration": 26,
    "start_time": "2021-09-16T15:53:28.014Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-16T15:53:28.042Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-16T15:53:28.066Z"
   },
   {
    "duration": 968,
    "start_time": "2021-09-16T15:53:28.091Z"
   },
   {
    "duration": 29,
    "start_time": "2021-09-16T15:53:29.066Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-16T15:53:29.097Z"
   },
   {
    "duration": 27,
    "start_time": "2021-09-16T15:53:29.106Z"
   },
   {
    "duration": 506,
    "start_time": "2021-09-16T15:53:29.135Z"
   },
   {
    "duration": 82,
    "start_time": "2021-09-16T15:53:29.644Z"
   },
   {
    "duration": 525,
    "start_time": "2021-09-16T15:53:29.729Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-16T15:53:30.257Z"
   },
   {
    "duration": 27,
    "start_time": "2021-09-16T15:53:30.271Z"
   },
   {
    "duration": 86,
    "start_time": "2021-09-16T15:53:30.300Z"
   },
   {
    "duration": 200,
    "start_time": "2021-09-16T15:53:30.389Z"
   },
   {
    "duration": 77,
    "start_time": "2021-09-16T15:53:30.591Z"
   },
   {
    "duration": 97,
    "start_time": "2021-09-16T15:53:30.671Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-16T15:53:30.770Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-16T15:53:30.789Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-16T15:53:30.805Z"
   },
   {
    "duration": 42,
    "start_time": "2021-09-16T15:53:30.825Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-16T15:53:30.870Z"
   },
   {
    "duration": 91,
    "start_time": "2021-09-16T15:53:30.881Z"
   },
   {
    "duration": 98,
    "start_time": "2021-09-16T15:53:30.975Z"
   },
   {
    "duration": 91,
    "start_time": "2021-09-16T15:53:31.076Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-16T15:53:31.170Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-16T15:53:31.183Z"
   },
   {
    "duration": 64,
    "start_time": "2021-09-16T15:53:31.204Z"
   },
   {
    "duration": 96,
    "start_time": "2021-09-16T15:53:31.271Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-16T15:53:31.370Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-16T15:53:31.377Z"
   },
   {
    "duration": 72,
    "start_time": "2021-09-16T15:53:31.401Z"
   },
   {
    "duration": 1194,
    "start_time": "2021-09-18T12:46:26.063Z"
   },
   {
    "duration": 79,
    "start_time": "2021-09-18T12:46:30.277Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-18T12:46:40.394Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-18T12:46:46.921Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-18T12:47:39.702Z"
   },
   {
    "duration": 1560,
    "start_time": "2021-09-20T11:07:09.096Z"
   },
   {
    "duration": 162,
    "start_time": "2021-09-20T11:07:19.833Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-20T11:07:51.545Z"
   },
   {
    "duration": 19,
    "start_time": "2021-09-20T11:07:53.575Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-20T11:07:57.107Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-20T11:14:24.178Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-20T11:14:26.140Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-20T11:14:33.582Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-20T11:14:37.504Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-20T11:14:41.245Z"
   },
   {
    "duration": 8737,
    "start_time": "2021-09-20T11:14:46.069Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-20T11:15:25.727Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-20T11:15:27.968Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-20T11:15:33.468Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-20T11:16:29.331Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-20T11:16:32.955Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-20T11:16:39.146Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-20T11:16:44.109Z"
   },
   {
    "duration": 1862,
    "start_time": "2021-09-22T11:39:42.863Z"
   },
   {
    "duration": 154,
    "start_time": "2021-09-22T11:39:47.757Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T11:39:49.806Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-22T11:39:52.179Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-22T11:39:54.934Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T11:39:57.604Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-22T11:40:00.153Z"
   },
   {
    "duration": 34,
    "start_time": "2021-09-22T11:40:03.005Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-22T11:40:05.841Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-22T11:40:09.002Z"
   },
   {
    "duration": 8544,
    "start_time": "2021-09-22T11:40:16.441Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-22T11:46:05.000Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-22T11:46:06.466Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-22T11:46:09.043Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-22T11:46:10.938Z"
   },
   {
    "duration": 26,
    "start_time": "2021-09-22T11:46:13.387Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-22T11:46:16.645Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-22T11:46:21.040Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-22T11:46:23.888Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-22T11:59:49.324Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-22T11:59:58.130Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-22T12:21:06.107Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-22T12:21:13.628Z"
   },
   {
    "duration": 22,
    "start_time": "2021-09-22T12:21:37.576Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-22T12:21:40.671Z"
   },
   {
    "duration": 23,
    "start_time": "2021-09-22T12:21:44.296Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-22T12:21:47.650Z"
   },
   {
    "duration": 189,
    "start_time": "2021-09-22T12:23:15.663Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T12:31:11.127Z"
   },
   {
    "duration": 148,
    "start_time": "2021-09-22T12:43:14.700Z"
   },
   {
    "duration": 1655,
    "start_time": "2021-09-22T13:06:01.011Z"
   },
   {
    "duration": 107,
    "start_time": "2021-09-22T13:06:02.669Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-22T13:06:02.780Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-22T13:06:02.788Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-22T13:06:02.824Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-22T13:06:02.836Z"
   },
   {
    "duration": 26,
    "start_time": "2021-09-22T13:06:02.851Z"
   },
   {
    "duration": 59,
    "start_time": "2021-09-22T13:06:02.883Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-22T13:06:02.945Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-22T13:06:02.960Z"
   },
   {
    "duration": 8749,
    "start_time": "2021-09-22T13:06:02.983Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-22T13:06:11.735Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-22T13:06:11.740Z"
   },
   {
    "duration": 21,
    "start_time": "2021-09-22T13:06:11.751Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-22T13:06:11.775Z"
   },
   {
    "duration": 25,
    "start_time": "2021-09-22T13:06:11.815Z"
   },
   {
    "duration": 36,
    "start_time": "2021-09-22T13:06:11.842Z"
   },
   {
    "duration": 51,
    "start_time": "2021-09-22T13:06:11.881Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-22T13:06:11.935Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T13:06:11.971Z"
   },
   {
    "duration": 42,
    "start_time": "2021-09-22T13:06:11.979Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T13:06:12.023Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-22T13:06:12.034Z"
   },
   {
    "duration": 15,
    "start_time": "2021-09-22T13:06:12.042Z"
   },
   {
    "duration": 10,
    "start_time": "2021-09-22T13:06:12.060Z"
   },
   {
    "duration": 109,
    "start_time": "2021-09-22T13:06:12.073Z"
   },
   {
    "duration": 95,
    "start_time": "2021-09-22T13:06:12.185Z"
   },
   {
    "duration": 1591,
    "start_time": "2021-09-22T13:06:12.283Z"
   },
   {
    "duration": 17,
    "start_time": "2021-09-22T13:06:13.877Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T13:06:13.916Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-22T13:06:13.924Z"
   },
   {
    "duration": 16,
    "start_time": "2021-09-22T13:06:13.934Z"
   },
   {
    "duration": 967,
    "start_time": "2021-09-22T13:06:13.953Z"
   },
   {
    "duration": 29,
    "start_time": "2021-09-22T13:06:14.923Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-22T13:06:14.954Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-22T13:06:14.964Z"
   },
   {
    "duration": 560,
    "start_time": "2021-09-22T13:06:14.975Z"
   },
   {
    "duration": 89,
    "start_time": "2021-09-22T13:06:15.537Z"
   },
   {
    "duration": 538,
    "start_time": "2021-09-22T13:06:15.628Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-22T13:06:16.168Z"
   },
   {
    "duration": 12,
    "start_time": "2021-09-22T13:06:16.179Z"
   },
   {
    "duration": 32,
    "start_time": "2021-09-22T13:06:16.193Z"
   },
   {
    "duration": 98,
    "start_time": "2021-09-22T13:06:16.229Z"
   },
   {
    "duration": 93,
    "start_time": "2021-09-22T13:06:16.330Z"
   },
   {
    "duration": 90,
    "start_time": "2021-09-22T13:06:16.427Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-22T13:06:16.519Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-22T13:06:16.528Z"
   },
   {
    "duration": 7,
    "start_time": "2021-09-22T13:06:16.535Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-22T13:06:16.545Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-22T13:06:16.618Z"
   },
   {
    "duration": 93,
    "start_time": "2021-09-22T13:06:16.630Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-22T13:06:16.726Z"
   },
   {
    "duration": 85,
    "start_time": "2021-09-22T13:06:16.737Z"
   },
   {
    "duration": 93,
    "start_time": "2021-09-22T13:06:16.825Z"
   },
   {
    "duration": 9,
    "start_time": "2021-09-22T13:06:16.921Z"
   },
   {
    "duration": 82,
    "start_time": "2021-09-22T13:06:16.934Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-22T13:06:17.020Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-22T13:06:17.028Z"
   },
   {
    "duration": 89,
    "start_time": "2021-09-22T13:06:17.036Z"
   },
   {
    "duration": 99,
    "start_time": "2021-09-22T13:06:17.128Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
